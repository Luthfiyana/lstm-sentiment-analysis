{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1tX3eGEE8sG"
      },
      "outputs": [],
      "source": [
        "#Import Library\n",
        "import pandas as pd\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Bidirectional\n",
        "from tensorflow.keras.models import load_model\n",
        "import gradio as gr #opsional untuk antarmuka pengguna\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eMnPUlC5-Z20",
        "outputId": "15d62c81-401d-40b5-9851-01967e2eb390"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('testing_converted.xlsx')\n",
        "\n",
        "print(\"Dataframe head:\")\n",
        "print(df.head())\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df.iloc[:, 0].apply(clean_text)\n",
        "df['Sentiment'] = df.iloc[:, 1]\n",
        "\n",
        "\n",
        "print(\"\\nDataframe head after cleaning text:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nInitial Sentiment Distribution:\")\n",
        "print(df['Sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0Fgfx9UN_dpT",
        "outputId": "5d3b91ba-7bd6-412f-c64b-23f12dd869ff"
      },
      "outputs": [],
      "source": [
        "TOKENIZER_PATH = '/content/drive/MyDrive/sentiment_model/tokenizer.pkl'\n",
        "MODEL_PATH = '/content/drive/MyDrive/sentiment_model/sentiment_lstm_model.h5'\n",
        "MAX_WORDS = 5000\n",
        "MAX_LEN = 100\n",
        "\n",
        "\n",
        "label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
        "df['label'] = df['Sentiment'].map(label_mapping)\n",
        "\n",
        "if df['label'].isnull().any():\n",
        "    print(\"Warning: Some sentiment labels could not be mapped. These rows will be dropped.\")\n",
        "    df.dropna(subset=['label'], inplace=True)\n",
        "\n",
        "df['label'] = df['label'].astype(int)\n",
        "\n",
        "X_original_texts = df['clean_text']\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(df['clean_text'])\n",
        "\n",
        "X = tokenizer.texts_to_sequences(df['clean_text'])\n",
        "X = pad_sequences(X, maxlen=MAX_LEN, padding='post')\n",
        "\n",
        "y = to_categorical(df['label'], num_classes=len(label_mapping))\n",
        "\n",
        "\n",
        "y_labels_for_weights = np.argmax(y, axis=1)\n",
        "\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_labels_for_weights), y=y_labels_for_weights)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "print(f\"Calculated class weights: {class_weight_dict}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test, X_train_original, X_test_original = train_test_split(\n",
        "    X, y, X_original_texts, test_size=0.1, random_state=42, stratify=y_labels_for_weights\n",
        ")\n",
        "\n",
        "print(f\"\\nShape of X_train (tokenized): {X_train.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of X_test (tokenized): {X_test.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")\n",
        "print(f\"Distribution of classes in y_train: {Counter(np.argmax(y_train, axis=1))}\")\n",
        "print(f\"Distribution of classes in y_test: {Counter(np.argmax(y_test, axis=1))}\")\n",
        "print(\"\\n--- 5 Data Latih Teks Asli (Sebelum Tokenisasi) ---\")\n",
        "print('\\n'.join(X_train_original.head().to_list()))\n",
        "print(\"\\n--- 5 Data Uji Teks Asli (Sebelum Tokenisasi) ---\")\n",
        "print('\\n'.join(X_test_original.head().to_list()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "hTCOouZwAsAg",
        "outputId": "6a04a250-b1e0-4e55-b38f-f0974ae4de5a"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(MODEL_PATH):\n",
        "    print(\"Loading existing model...\")\n",
        "    model = load_model(MODEL_PATH)\n",
        "    with open(TOKENIZER_PATH, 'rb') as handle:\n",
        "        tokenizer = pickle.load(handle)\n",
        "else:\n",
        "    print(\"Building and training new model...\")\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LEN))\n",
        "    model.add(SpatialDropout1D(0.3))\n",
        "    model.add(Bidirectional(LSTM(100, dropout=0.3, recurrent_dropout=0.3)))\n",
        "    model.add(Dense(len(label_mapping), activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    print(\"\\nModel Summary:\")\n",
        "    model.summary()\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=10, batch_size=64,\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        class_weight=class_weight_dict)\n",
        "\n",
        "    model.save(MODEL_PATH)\n",
        "    with open(TOKENIZER_PATH, 'wb') as handle:\n",
        "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    print(\"\\nModel and tokenizer saved.\")\n",
        "\n",
        "print(\"\\nEvaluating model on test set...\")\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred = model.predict(X_test, verbose=0)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "labels = list(label_mapping.keys())\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "print(\"\\nClassification Report on Test Set:\")\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=list(label_mapping.keys())))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
